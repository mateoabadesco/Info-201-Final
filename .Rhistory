# How many people attended this campus event? Find out by using a built-in R function
length(attendees)
# Extract the third value in the vector attendees
attendees[3]
# Load the stringr library
library(stringr)
# Use a stringr function to find out how many professors were at the event
# First, create a Boolean vector (e.g. TRUE FALSE TRUE) that corresponds to each person in the attendees vector and whether or not they are a professor
str_detect(attendees, "Prof")
# Now, use a built-in R function to count how many professors were at the event (i.e., how many TRUE values are in the Boolean vector)
sum(str_detect(attendees, "Prof"))
# Load the stringr library
install.packages("stringr")
# Use a stringr function to find out how many professors were at the event
# First, create a Boolean vector (e.g. TRUE FALSE TRUE) that corresponds to each person in the attendees vector and whether or not they are a professor
str_detect(attendees, "Prof")
# Add in the necessary code to make these names a vector and assign it to the variable below
attendees <- c.("Rachel SR", "Prof. Walsh, PhD", "Vera FR", "Prof. Hendry, PhD", "Lily JR", "Najma SR", "Prof. Baeten MD", "Prof. Chu, MD", "Li FR")
# How many people attended this campus event? Find out by using a built-in R function
length(attendees)
# Extract the third value in the vector attendees
attendees[3]
# Load the stringr library
install.packages("stringr")
# Use a stringr function to find out how many professors were at the event
# First, create a Boolean vector (e.g. TRUE FALSE TRUE) that corresponds to each person in the attendees vector and whether or not they are a professor
str_detect(attendees, "Prof")
# Now, use a built-in R function to count how many professors were at the event (i.e., how many TRUE values are in the Boolean vector)
sum(str_detect(attendees, "Prof"))
# Now, use a different stringr function to find out the year or degree of each student/professor — i.e., extract the last 3 letters from every string in the attendees vector
str_sub(attendees, -3)
# Use another built-in R function to identify only the unique years/degrees (no repeats)
unique(str_sub(attendees, -3))
# Use another built-in R function to calculate how many total unique years/degrees there are
length(unique(str_sub(attendees, -3)))
# Add in the necessary code to make these names a vector and assign it to the variable below
attendees <- c.("Rachel SR", "Prof. Walsh, PhD", "Vera FR", "Prof. Hendry, PhD", "Lily JR", "Najma SR", "Prof. Baeten MD", "Prof. Chu, MD", "Li FR")
# How many people attended this campus event? Find out by using a built-in R function
length(attendees)
# Add in the necessary code to make these names a vector and assign it to the variable below
attendees <- c("Rachel SR", "Prof. Walsh, PhD", "Vera FR", "Prof. Hendry, PhD", "Lily JR", "Najma SR", "Prof. Baeten MD", "Prof. Chu, MD", "Li FR")
# How many people attended this campus event? Find out by using a built-in R function
length(attendees)
# Extract the third value in the vector attendees
attendees[3]
# Load the stringr library
library(stringr)
# Use a stringr function to find out how many professors were at the event
# First, create a Boolean vector (e.g. TRUE FALSE TRUE) that corresponds to each person in the attendees vector and whether or not they are a professor
str_detect(attendees, "Prof")
# Now, use a built-in R function to count how many professors were at the event (i.e., how many TRUE values are in the Boolean vector)
sum(str_detect(attendees, "Prof"))
# Now, use a different stringr function to find out the year or degree of each student/professor — i.e., extract the last 3 letters from every string in the attendees vector
str_sub(attendees, -3)
# Use another built-in R function to identify only the unique years/degrees (no repeats)
unique(str_sub(attendees, -3))
# Create a vector `names` that contains your name and the names of 2 other students. Print the vector.
names <- c.("Ryan", "Autumn", "Sartu")
# Create a vector `names` that contains your name and the names of 2 other students. Print the vector.
names <- c("Ryan", "Autumn", "Sartu")
print(names)
# Create a vector `names` that contains your name and the names of 2 other students. Print the vector.
names <- c("Ryan", "Autumn", "Sartu")
print(names)
# Use the colon operator : to create a vector `n` of numbers from 10:49
n <- 10:49
# Use the `length()` function to get the number of elements in `n`
length(n)
# Add 1 to each element in `n` and print the result
print(n + 1)
# Create a vector `m` that contains the numbers 10 to 1 (in that order).
# Hint: use the `seq()` function
m <- seq(10, 1)
# Subtract `m` FROM `n`. Note the recycling!
sub <- n - m
print(sub)
# Use the `seq()` function to produce a range of numbers from -5 to 10 in `0.1`
# increments. Store it in a variable `x_range`
x_range <- seq(-5, 10, 0.1)
# Create a vector `sin_wave` by calling the `sin()` function on each element
# in `x_range`.
sin_wave <- sin(x_range)
# Create a vector `cos_wave` by calling the `cos()` function on each element
# in `x_range`.
cos_wave <- cos(x_range)
# Create a vector `wave` by multiplying `sin_wave` and `cos_wave` together, then
# adding `sin_wave` to the product
wave <- sin_wave * cos_wave + sin_wave
# Use the `plot()` function to plot your `wave`!
plot(wave)
# Now change the value of the office_temperature, and test the conditional again to make sure it works
# Now change the value of the office_temperature, and test the conditional again to make sure it works
# Now change the value of the office_temperature, and test the conditional again to make sure it works
# Now change the value of the office_temperature, and test the conditional again to make sure it works
# Extract the third value in the vector attendees
attendees[3]
# Load the stringr library
install.packages("stringr")
install.packages("stringr")
# Use a stringr function to find out how many professors were at the event
# First, create a Boolean vector (e.g. TRUE FALSE TRUE) that corresponds to each person in the attendees vector and whether or not they are a professor
str_detect(attendees, "Prof")
# Now, use a built-in R function to count how many professors were at the event (i.e., how many TRUE values are in the Boolean vector)
sum(str_detect(attendees, "Prof"))
# Now, use a different stringr function to find out the year or degree of each student/professor — i.e., extract the last 3 letters from every string in the attendees vector
str_sub(attendees, -3)
# Use another built-in R function to identify only the unique years/degrees (no repeats)
unique(str_sub(attendees, -3))
# Use another built-in R function to calculate how many total unique years/degrees there are
length(unique(str_sub(attendees, -3)))
# Load the stringr library
library("stringr")
# Use a stringr function to find out how many professors were at the event
# First, create a Boolean vector (e.g. TRUE FALSE TRUE) that corresponds to each person in the attendees vector and whether or not they are a professor
str_detect(attendees, "Prof")
# Now, use a built-in R function to count how many professors were at the event (i.e., how many TRUE values are in the Boolean vector)
sum(str_detect(attendees, "Prof"))
# Add in the necessary code to make these names a vector and assign it to the variable below
attendees <- c.("Rachel SR", "Prof. Walsh, PhD", "Vera FR", "Prof. Hendry, PhD", "Lily JR", "Najma SR", "Prof. Baeten MD", "Prof. Chu, MD", "Li FR")
# How many people attended this campus event? Find out by using a built-in R function
length(attendees)
# Extract the third value in the vector attendees
attendees[3]
# Load the stringr library
library("stringr")
# Use a stringr function to find out how many professors were at the event
# First, create a Boolean vector (e.g. TRUE FALSE TRUE) that corresponds to each person in the attendees vector and whether or not they are a professor
str_detect(attendees, "Prof")
# Now, use a built-in R function to count how many professors were at the event (i.e., how many TRUE values are in the Boolean vector)
sum(str_detect(attendees, "Prof"))
# Now, use a different stringr function to find out the year or degree of each student/professor — i.e., extract the last 3 letters from every string in the attendees vector
str_sub(attendees, -3)
# Use another built-in R function to identify only the unique years/degrees (no repeats)
unique(str_sub(attendees, -3))
# Use another built-in R function to calculate how many total unique years/degrees there are
length(unique(str_sub(attendees, -3)))
source("C:/Users/4nime/Desktop/School/Info 201/lists.R")
source("C:/Users/4nime/Desktop/School/Info 201/lists.R")
source("C:/Users/4nime/Desktop/School/Info 201/lists.R")
source("C:/Users/4nime/Desktop/School/Info 201/lists.R")
source("C:/Users/4nime/Desktop/School/Info 201/Exercise-8-1.R")
source("C:/Users/4nime/Desktop/School/Info 201/Exercise-8-1.R")
# Use double-bracket notation to extract your `my_lunch` element from your list
# and save it in your list as the element at index 5 (no reason beyond practice)
meals[[5]] <- meals[["my_lunch"]]
# Create a vector `my_breakfast` of everything you ate for breakfast
my_breakfast <- c("cereal", "milk")
# Create a vector `my_lunch` of everything you ate (or will eat) for lunch
my_lunch <- c("chicken", "lemondade", "cauliflower")
# Create a list `meals` that has contains your breakfast and lunch (remember to label your list elements using `=`)
meals = list(breakfast = my_breakfast, lunch = my_lunch)
# Add a "dinner" element to your `meals` list that has what you plan to eat
# for dinner
meals$dinner = c("pizza")
dinner = meals$dinner
# Use double-bracket notation to extract your `my_lunch` element from your list
# and save it in your list as the element at index 5 (no reason beyond practice)
meals[[5]] <- meals[["my_lunch"]]
# Use single-bracket notation and index numbers to extract your breakfast
# and lunch from your list and save them to a list called `early_meals`
early_meals <- meals[1:2]
# Use double-bracket notation to extract your `my_lunch` element from your list
# and save it in your list as the element at index 5 (no reason beyond practice)
meals[[5]] <- meals[["lunch"]]
# Use single-bracket notation and index numbers to extract your breakfast
# and lunch from your list and save them to a list called `early_meals`
early_meals <- meals[1:2]
# Use `lapply()` to apply the `round()` function to each number in the list of numbers. Try rounding by 1 digit and then 2 digits
lapply(round(numbers, 1))
numbers <- as.list(runif(10))
# Use `lapply()` to apply the `round()` function to each number in the list of numbers. Try rounding by 1 digit and then 2 digits
lapply(round(numbers, 1))
source("C:/Users/4nime/Desktop/School/Info 201/Exercise-8-2.R")
# Load the data from the following URL
# https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv
# Save as np_data
np_data <- read.csv(url("https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv"))
# Load the data from the following URL
# https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv
# Save as np_data
np_data <- read.csv(url("https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv"))
View(np_data)
# Add a new column "park_state" to the dataframe that combines the name of each National Park and the state in which it is located like so
# Olympic NP, WA
np_data$park_state <- paste(np_data$ParkName, np_data$State, sep=", ")
View(np_data)
# Exploring visits to National Parks through data
library(dyplr)
# Exploring visits to National Parks through data
library(dlypr)
# Exploring visits to National Parks through data
library(dylpr)
# Exploring visits to National Parks through data
library(dplyr)
# What is the single greatest number of Recreation Visits for any National Park in any year?
# Save this filtered row as max_visits_row
max_vists_row <- np_data %>% summarize(np_data, np_data$ParkName, max(np_data$RecreationVisits))
# What is the single greatest number of Recreation Visits for any National Park in any year?
# Save this filtered row as max_visits_row
max_vists_row <- np_data %>% summarize(np_data, ParkName, max(np_data$RecreationVisits))
# Add a new column "park_state" to the dataframe that combines the name of each National Park and the state in which it is located like so
# Olympic NP, WA
np_data$park_state <- paste(np_data$ParkName, np_data$State, sep=", ")
# What is the single greatest number of Recreation Visits for any National Park in any year?
# Save this filtered row as max_visits_row
max_visits_row <- np_data %>%
filter(RecreationVisits == max(RecreationVisits))
# Load the data from the following URL
# https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv
# Save as np_data
np_data <- read.csv(url("https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv"))
# Add a new column "park_state" to the dataframe that combines the name of each National Park and the state in which it is located like so
# Olympic NP, WA
np_data$park_state <- paste(np_data$ParkName, np_data$State, sep=", ")
# What is the single greatest number of Recreation Visits for any National Park in any year?
# Save this filtered row as max_visits_row
max_visits_row <- np_data %>%
filter(RecreationVisits == max(RecreationVisits))
# Now "pull" only the max number of visits and save as max_visits
max_visits <- max_visits_row$RecreationVisits
# What is the average number of visits for each National Park from 1979-2020?
# Save as avg_visits
# NOTE: You probably won't be able to answer this question without a new DPLYR concept, but make your best effort and try to identify what steps are missing
avg_visits <- np_data %>%
group_by(ParkName) %>%
summarize(avg_visits = mean(RecreationVisits))
# Find the average number of visits for each state
# Save as avg_state_visits and View()
# What state has the most and least average visits?
# What patterns or surprises do you notice?
most <- avg_visits %>% filter(RecreationVisits = max(RecreationVisits))
# Find the average number of visits for each National Park
# Save as avg_park_visits and View()
# What park has the most and least average visits?
# What patterns or surprises do you notice?
avg_visits <- np_data %>%
group_by(ParkName) %>%
summarize(avg_visits = mean(RecreationVisits))
# Find the average number of visits for each state
# Save as avg_state_visits and View()
# What state has the most and least average visits?
# What patterns or surprises do you notice?
most <- avg_visits %>% filter(RecreationVisits = max(RecreationVisits))
# Load the National Park data from the following URL
# https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv
# Save as np_data
library(dplyr)
np_data <- read.csv(url("https://raw.githubusercontent.com/melaniewalsh/Neat-Datasets/main/1979-2020-National-Park-Visits-By-State.csv"))
# Find the average number of visits for each National Park
# Save as avg_park_visits and View()
# What park has the most and least average visits?
# What patterns or surprises do you notice?
avg_visits <- np_data %>%
group_by(ParkName) %>%
summarize(avg_visits = mean(RecreationVisits))
# Find the average number of visits for each state
# Save as avg_state_visits and View()
# What state has the most and least average visits?
# What patterns or surprises do you notice?
most <- avg_visits %>% filter(RecreationVisits = max(RecreationVisits))
# Find the average number of visits for each state
# Save as avg_state_visits and View()
# What state has the most and least average visits?
# What patterns or surprises do you notice?
most <- avg_visits %>% filter(RecreationVisits == max(RecreationVisits))
# Find the average number of visits for each state
# Save as avg_state_visits and View()
# What state has the most and least average visits?
# What patterns or surprises do you notice?
most <- avg_visits %>% filter(RecreationVisits == max(RecreationVisits))
# Find the average number of visits for each state
# Save as avg_state_visits and View()
# What state has the most and least average visits?
# What patterns or surprises do you notice?
most <- avg_visits %>%
filter(RecreationVisits == max(RecreationVisits))
# Find the average number of visits for each state
# Save as avg_state_visits and View()
# What state has the most and least average visits?
# What patterns or surprises do you notice?
most <- avg_visits %>%
filter(avg_visits == max(avg_visits))
# Find the number of distinct parks for each state
# Save as distinct_parks
# Which state has the most national parks?
# What patterns or surprises do you notice?
distinct_parks <- np_data %>%
group_by(State)
View(distinct_parks)
View(distinct_parks)
# Find the number of distinct parks for each state
# Save as distinct_parks
# Which state has the most national parks?
# What patterns or surprises do you notice?
distinct_parks <- np_data %>%
group_by(State) %>%
summarize(distinct_parks = n_distinct(ParkName))
# Load the data from the following URL
# https://github.com/melaniewalsh/Neat-Datasets/raw/main/Survivor-Viewers.csv
# Save as survivor_df
survior_df <- read.csv(url("https://github.com/melaniewalsh/Neat-Datasets/raw/main/Survivor-Viewers.csv") )
# Calculate the average number of viewers for each season `avg_viewers`
avg_viewers <- mean(survior_df$viewers, na.rm = TRUE)
# Calculate the average number of viewers for each season `avg_viewers`
avg_viewers <- mean((survior_df %>% group_by(season))$viewers, na.rm = TRUE)
# Calculate the average number of viewers for each season `avg_viewers`
avg_viewers <- mean((survior_df %>% group_by(season))$viewers, na.rm = TRUE)
# Load the DPLYR library
library(dplyr)
# Calculate the average number of viewers for each season `avg_viewers`
avg_viewers <- mean((survior_df %>% group_by(season))$viewers, na.rm = TRUE)
# Calculate the average number of viewers for each season `avg_viewers`
avg_viewers <- survior_df %>% group_by(season)
View(avg_viewers)
# Calculate the average number of viewers for each season `avg_viewers`
avg_viewers <- survior_df %>% group_by(season) %>% summarize(views = mean(viewers))
View(avg_viewers)
# Calculate the average number of viewers for each season `avg_viewers`
avg_viewers <- survior_df %>% group_by(season) %>% summarize(views = mean(viewers, na.rm = TRUE))
View(avg_viewers)
# Find the episode with the most number of viewers `most_views_row`
Your code here
# For fun, let's make a plot of avg viewers over season number
plot(avg_viewers)
# Find the episode with the most number of viewers `most_views_row`
most_views_row <- survior_df %>% filter(viewers == max(survior_df$viewers))
# Find the episode with the most number of viewers, then pull the number of viewers and save it as a variable `most_views`
most_views = most_views_row$viewers
# Install package/data
install.packages("nycflights13")
# Load necessary libraries
library("nycflights13")
library("dplyr")
# Load dataframes
flights <- flights
airlines <- airlines
airports <- airports
# What was the average departure delay in each month?
# Save this as a data frame `dep_delay_by_month`
# Hint: you'll have to perform a grouping operation then summarize your data
dep_delay_by_month <- flights %>% group_by(month) %>% summarise(delay = mean(dep_delay))
View(dep_delay_by_month)
# What was the average departure delay in each month?
# Save this as a data frame `dep_delay_by_month`
# Hint: you'll have to perform a grouping operation then summarize your data
dep_delay_by_month <- flights %>% group_by(month) %>% summarise(delay = mean(dep_delay, na.rm = TRUE))
View(dep_delay_by_month)
# If your above data frame contains just two columns (e.g., "month", and "delay" in that order), you can create a scatterplot by passing that data frame to the built-in `plot()` function
plot(dep_delay_by_month, type = 'b')
# Use `left_join()` to join the "flights" dataframe to the "airlines" dataframe, which has the airline information
left_join(flights, airlines)
# What was the average departure delay for each airline?
# Hint: you'll have to perform a grouping operation then summarize your data
dep_delay_by_airline <- flights %>% group_by(airlines) %>% summarise(delay = mean(dep_delay, na.rm = TRUE))
# What was the average departure delay for each airline?
# Hint: you'll have to perform a grouping operation then summarize your data
dep_delay_by_airline <- flights %>% group_by(airlines) %>% summarise(delay = mean(dep_delay, na.rm = TRUE))
# What was the average departure delay for each airline?
# Hint: you'll have to perform a grouping operation then summarize your data
dep_delay_by_airline <- flights %>% group_by(airlines) %>% summarise(delay = mean(dep_delay, na.rm = TRUE))
# Load dataframes
flights <- flights
# What was the average departure delay for each airline?
# Hint: you'll have to perform a grouping operation then summarize your data
dep_delay_by_airline <- flights %>% group_by(airlines) %>% summarise(delay = mean(dep_delay, na.rm = TRUE))
View(airlines)
# Use `left_join()` to join the "flights" dataframe to the "airlines" dataframe, which has the airline information
flights <- left_join(flights, airlines)
# What was the average departure delay for each airline?
# Hint: you'll have to perform a grouping operation then summarize your data
dep_delay_by_airline <- flights %>% group_by(airlines) %>% summarise(delay = mean(dep_delay, na.rm = TRUE))
# Load dataframes
flights <- flights
airlines <- airlines
airports <- airports
# What was the average departure delay in each month?
# Save this as a data frame `dep_delay_by_month`
# Hint: you'll have to perform a grouping operation then summarize your data
dep_delay_by_month <- flights %>% group_by(month) %>% summarise(delay = mean(dep_delay, na.rm = TRUE))
# If your above data frame contains just two columns (e.g., "month", and "delay" in that order), you can create a scatterplot by passing that data frame to the built-in `plot()` function
plot(dep_delay_by_month, type = 'b')
# Use `left_join()` to join the "flights" dataframe to the "airlines" dataframe, which has the airline information
flights_airlines <- left_join(flights, airlines)
# What was the average departure delay for each airline?
# Hint: you'll have to perform a grouping operation then summarize your data
dep_delay_by_airline <- flights_airlines %>%
group_by(name) %>%
summarize(delay = mean(dep_delay, na.rm = TRUE))
View(dep_delay_by_airline)
View(flights_airlines)
item_df <- data.frame(
item_name = c("apple", "orange", "m&m", "skittles", "fancy chocolate"),
item_price = c(1, 0.5, 1.5, 1.5, 7),
item_type = c("fruit", "fruit", "candy", "candy", "candy")
)
user_cart_df <- data.frame (
item_name = c("apple", "m&m", "skittles"),
quantity = c(3, 5, 2)
)
total <_
package.install(plotly)
packages.install(plotly)
packages.install("plotly")
install.packages("plotly")
library(ggplot2)
ggplot(data=mpg) +
geom_point(mapping = aes(x=displ, y =hwy))
ggplot(data=mpg) +
geom_point(mapping = aes(x=displ, y =hwy)) +
facet_wrap(~class)
np_data <- read.csv("https://github.com/melaniewalsh/Neat-Datasets/raw/main/1979-2020-National-Park-Visits-By-State.csv")
np_data <- read.csv("https://github.com/melaniewalsh/Neat-Datasets/raw/main/1979-2020-National-Park-Visits-By-State.csv")
# Install relevant libraries
install.packages("scales")
install.packages("scales")
install.packages("scales")
install.packages("scales")
install.packages("scales")
# Load relevant libraries
library("scales")
library("dplyr")
library("ggplot2")
View(np_data)
# Exercise 1: You're going to compare the recreation visits over time for at least 2 National Parks
# Explore np_data and pick at least 2 NPs that would be interesting to compare
# Filter the data for those 2 or more NPs
my_parks <- np_data %>%
filter(ParkName %in% c("Arches NP", "Canyonlands NP"))
# Exercise 2: Make a line plot of your 2 or more NPs, and color the lines by the names of the park
# See what the plot looks like before you turn off scientific notation, and then turn off scientific notation by uncommenting and running the line below
# options(scipen = 999)
ggplot(my_parks) +
geom_line(aes(x = Year, y = RecreationVisits, color = ParkName))
# Exercise 4: Make a line plot of your 2 or more NPs, and color the lines by the names of the park
# Additionally, choose a new color palette
# Also, add a significant, attention-grabbing title and legible x, y axes labels
# Finally, format the x tick labels so that they appear every 5 years, and change the y axis to abbreviated thousands (k) and millions (m)
ggplot(my_parks) +
geom_line(aes(x = Year, y = RecreationVisits, color = ParkName)) +
scale_color_brewer(palette = "Set2") +
labs(title = "Arches Overtakes the CanyonLands in the 21st Century", x = "Year", y = "Number of Visits") +
scale_x_continuous(breaks = seq(1980, 2020, 5)) +
scale_y_continuous(labels = label_number_si())
# Exercise 3: Make a line plot of your 2 or more NPs, and color the lines by the names of the park
# Additionally, choose a new color palette
# Possible color palettes: https://r-graph-gallery.com/38-rcolorbrewers-palettes.html
# Also, add a significant, attention-grabbing title and legible x, y axes labels
ggplot(my_parks) +
geom_line(aes(x = Year, y = RecreationVisits, color = ParkName)) +
scale_color_brewer(palette = "Set2") +
labs(title = "Arches Overtakes the Badlands in the 21st Century", x = "Year", y = "Number of Visits")
# Exercise 4: Make a line plot of your 2 or more NPs, and color the lines by the names of the park
# Additionally, choose a new color palette
# Also, add a significant, attention-grabbing title and legible x, y axes labels
# Finally, format the x tick labels so that they appear every 5 years, and change the y axis to abbreviated thousands (k) and millions (m)
ggplot(my_parks) +
geom_line(aes(x = Year, y = RecreationVisits, color = ParkName)) +
scale_color_brewer(palette = "Set2") +
labs(title = "Arches Overtakes the CanyonLands in the 21st Century", x = "Year", y = "Number of Visits") +
scale_x_continuous(breaks = seq(1980, 2020, 5)) +
scale_y_continuous(labels = label_number_si())
# Exercise 4: Make a line plot of your 2 or more NPs, and color the lines by the names of the park
# Additionally, choose a new color palette
# Also, add a significant, attention-grabbing title and legible x, y axes labels
# Finally, format the x tick labels so that they appear every 5 years, and change the y axis to abbreviated thousands (k) and millions (m)
ggplot(my_parks) +
geom_line(aes(x = Year, y = RecreationVisits, color = ParkName)) +
scale_color_brewer(palette = "Set2") +
labs(title = "Arches Overtakes the CanyonLands in the 21st Century", x = "Year", y = "Number of Visits") +
scale_x_continuous(breaks = seq(1980, 2020, 5))
shiny::runApp('C:/Users/4nime/Desktop/School/Info 201')
runApp('C:/Users/4nime/Desktop/School/Info 201')
runApp('C:/Users/4nime/Desktop/School/Info 201')
runApp('C:/Users/4nime/Desktop/School/Info 201')
runApp('C:/Users/4nime/Desktop/School/Info 201')
runApp('C:/Users/4nime/Desktop/School/Info 201')
runApp('C:/Users/4nime/Desktop/School/Info 201')
runApp('C:/Users/4nime/Desktop/School/Info 201')
runApp('C:/Users/4nime/Desktop/School/Info 201')
runApp('C:/Users/4nime/Desktop/School/Info 201')
rm(list = ls())
library("dplyr")
library("ggplot2")
library("stringr")
library("tidyr")
setwd("C:\\Users\\4nime\\Desktop\\School\\Info 201\\Info-201-Final")
homelessness_2023_df <- read.csv("2023-HIC-Counts-by-State.csv")
homelessness_2022_df <- read.csv("2022-HIC-Counts-by-State.csv")
homelessness_2021_df <- read.csv("2021-HIC-Counts-by-State.csv")
property_df <- read.csv("HPI_master.csv")
homelessness_df <- merge(homelessness_2021_df, homelessness_2022_df, all = TRUE)
homelessness_df <- merge(homelessness_df, homelessness_2023_df, all =  TRUE)
homelessness_df$yearState <- paste(homelessness_df$year, homelessness_df$CocState, sep = " ")
PIT_df <- homelessness_df %>% group_by(yearState) %>% summarize(total_estimate = sum(PIT.Count, na.rm = TRUE))
property_df <- property_df %>% filter(level == "State") %>% filter(yr > 2020)
property_df$yearState <- paste(property_df$yr, property_df$place_id, sep = " ")
Price_df <- property_df %>% group_by(yearState) %>% summarize(total_estimate = mean(index_nsa, na.rm = TRUE))
joined_df <- left_join(Price_df, PIT_df, by = "yearState")
column_names <- colnames(joined_df)
print(column_names)
# Data cleaning
# Check for missing values in each column
apply(joined_df, 2, function(x) any(is.na(x)))
# From our output, we have no missing values
# Lets create a new categorical variable by Separating YearState Column
joined_df <- separate(joined_df, yearState, into = c("year", "state"), sep = " ")
joined_df
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
